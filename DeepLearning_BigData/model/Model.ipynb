{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Reproductibilité\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(SEED)\n",
        "\n",
        "# Chargement du fichier CSV\n",
        "df = pd.read_csv('cleaned_dataset.csv')\n",
        "print(\"Colonnes disponibles :\", df.columns)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# Prétraitement des données\n",
        "def preprocess_data(df, vocab, tokenizer):\n",
        "    # Tokeniser chaque texte et construire les indices de vocabulaire\n",
        "    texts = [torch.tensor(vocab(tokenizer(text)), dtype=torch.long) for text in df['text']]\n",
        "    labels = torch.tensor(df['target'].values, dtype=torch.float)  # Utilisation de 'target' comme label\n",
        "    return texts, labels\n",
        "\n",
        "# Construction du vocabulaire\n",
        "def build_vocab_from_df(df, tokenizer):\n",
        "    # Tokeniser chaque texte et construire le vocabulaire\n",
        "    tokenizer_gen = (tokenizer(text) for text in df['text'])\n",
        "    vocab = build_vocab_from_iterator(tokenizer_gen, specials=[\"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "# Construction du vocabulaire\n",
        "vocab = build_vocab_from_df(df, tokenizer)\n",
        "\n",
        "# Prétraitement des données\n",
        "texts, labels = preprocess_data(df, vocab, tokenizer)\n",
        "\n",
        "# Affichage de la taille du vocabulaire et de quelques exemples de texte tokenisés\n",
        "print(f\"Taille du vocabulaire: {len(vocab)}\")\n",
        "print(f\"Exemple de texte tokenisé : {texts[0]}\")\n",
        "\n",
        "# Split en train, validation, test\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=SEED)\n",
        "train_texts, valid_texts, train_labels, valid_labels = train_test_split(train_texts, train_labels, test_size=0.25, random_state=SEED)\n",
        "\n",
        "# Padding des séquences de texte (en fonction de la longueur maximale)\n",
        "def pad_sequence(texts, max_len):\n",
        "    return [torch.cat([text, torch.zeros(max_len - len(text))]) if len(text) < max_len else text[:max_len] for text in texts]\n",
        "\n",
        "# Définir la longueur maximale des séquences\n",
        "MAX_LEN = max([len(text) for text in train_texts])  # Utiliser la longueur maximale des textes d'entraînement\n",
        "\n",
        "# Padding des séquences\n",
        "train_texts = pad_sequence(train_texts, MAX_LEN)\n",
        "valid_texts = pad_sequence(valid_texts, MAX_LEN)\n",
        "test_texts = pad_sequence(test_texts, MAX_LEN)l\n",
        "\n",
        "# Création des DataLoader\n",
        "train_data = TensorDataset(torch.stack(train_texts), train_labels)\n",
        "valid_data = TensorDataset(torch.stack(valid_texts), valid_labels)\n",
        "test_data = TensorDataset(torch.stack(test_texts), test_labels)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Modèle RNN\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
        "                           bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        text = text.long()  # Ajoutez cette ligne pour convertir en LongTensor\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths=[len(t) for t in text], batch_first=True, enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)) if self.rnn.bidirectional else hidden[-1,:,:]\n",
        "        return self.fc(hidden)\n",
        "\n",
        "# Hyperparamètres\n",
        "INPUT_DIM = len(vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3  # Nombre de couches augmentées\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Instanciation du modèle\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
        "model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Optimiseur et fonction de perte\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Ajustement du taux d'apprentissage\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = criterion.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "# Early Stopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "# Fonction d'entraînement\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, label = batch\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Fonction d'évaluation\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, label = batch\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, label)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Fonction pour évaluer l'accuracy\n",
        "def accuracy(model, iterator):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, label = batch\n",
        "            predictions = model(text).squeeze(1)\n",
        "            preds = torch.round(torch.sigmoid(predictions))\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    return accuracy_score(all_labels, all_preds)\n",
        "\n",
        "# Entraînement du modèle avec Early Stopping\n",
        "N_EPOCHS = 10  # Augmentation du nombre d'époques\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion)\n",
        "    valid_acc = accuracy(model, valid_loader)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
        "    print(f\"\\tVal. Loss: {valid_loss:.3f}\")\n",
        "    print(f\"\\tVal. Accuracy: {valid_acc*100:.2f}%\")\n",
        "\n",
        "    # Vérification de l'early stopping\n",
        "    early_stopping(valid_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "# Charger le meilleur modèle\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS9KEFZQLrRZ",
        "outputId": "5e2eb5e9-8951-434c-c723-65e484c057bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colonnes disponibles : Index(['target', 'text'], dtype='object')\n",
            "Taille du vocabulaire: 62349\n",
            "Exemple de texte tokenisé : tensor([ 527,   16,   41,    4, 1329,    7, 3977,   44, 1427, 5804,   13, 1872,\n",
            "          33,    2,   20,    9,  151])\n",
            "Epoch: 1\n",
            "\tTrain Loss: 0.623\n",
            "\tVal. Loss: 0.553\n",
            "\tVal. Accuracy: 72.15%\n",
            "Epoch: 2\n",
            "\tTrain Loss: 0.545\n",
            "\tVal. Loss: 0.504\n",
            "\tVal. Accuracy: 75.37%\n",
            "Epoch: 3\n",
            "\tTrain Loss: 0.506\n",
            "\tVal. Loss: 0.492\n",
            "\tVal. Accuracy: 76.72%\n",
            "Epoch: 4\n",
            "\tTrain Loss: 0.476\n",
            "\tVal. Loss: 0.477\n",
            "\tVal. Accuracy: 77.18%\n",
            "Epoch: 5\n",
            "\tTrain Loss: 0.454\n",
            "\tVal. Loss: 0.477\n",
            "\tVal. Accuracy: 77.81%\n",
            "Epoch: 6\n",
            "\tTrain Loss: 0.434\n",
            "\tVal. Loss: 0.476\n",
            "\tVal. Accuracy: 78.25%\n",
            "Epoch: 7\n",
            "\tTrain Loss: 0.419\n",
            "\tVal. Loss: 0.477\n",
            "\tVal. Accuracy: 77.82%\n",
            "Epoch: 8\n",
            "\tTrain Loss: 0.402\n",
            "\tVal. Loss: 0.483\n",
            "\tVal. Accuracy: 78.34%\n",
            "Epoch: 9\n",
            "\tTrain Loss: 0.389\n",
            "\tVal. Loss: 0.482\n",
            "\tVal. Accuracy: 78.50%\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.376\n",
            "\tVal. Loss: 0.477\n",
            "\tVal. Accuracy: 78.64%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation sur le jeu de test\n",
        "test_loss = evaluate(model, test_loader, criterion)\n",
        "test_acc = accuracy(model, test_loader)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.3f}\")\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP4qzEFx68UQ",
        "outputId": "517984ed-f7a6-4935-f0b8-ef4a5145b0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.466\n",
            "Test Accuracy: 78.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Fuming with anger after a heated argument.\"\n",
        "sentiment, prob = predict_sentiment(model, sentence, vocab, tokenizer, MAX_LEN)\n",
        "\n",
        "print(f\"Phrase: {sentence}\")\n",
        "print(f\"Sentiment: {sentiment} (Probabilité: {prob:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFR80TdH8egl",
        "outputId": "7aa759e4-bbf3-4233-e23d-6466936871a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phrase: Fuming with anger after a heated argument.\n",
            "Sentiment: Négatif (Probabilité: 0.52)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}